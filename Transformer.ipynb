{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Braindecode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go1ZheUTdrka"
      },
      "source": [
        "# Install, imports, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfgvO0LYmmoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984cae01-a182-4d88-e782-f7b3b24c8680"
      },
      "source": [
        "!pip install -U https://github.com/NeuroTechX/moabb/archive/master.zip\n",
        "!pip install braindecode\n",
        "!wget -O feature_extraction.py https://raw.githubusercontent.com/skyli42/CSC413S2021-Team-22/master/feature_extraction.py \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/NeuroTechX/moabb/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/NeuroTechX/moabb/archive/master.zip\n",
            "\u001b[K     \\ 798kB 20.9MB/s\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML<6.0.0,>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 15.3MB/s \n",
            "\u001b[?25hCollecting pyunpack<0.3.0,>=0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting pyriemann>=0.2.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/5e/1df5684d9f43b574d7e2807869578750da94286508ab2129d62c26c1eef0/pyriemann-0.2.6-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting scipy<2.0,>=1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/91/ee427c42957f8c4cbe477bf4f8b7f608e003a17941e509d1777e58648cb3/scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 103kB/s \n",
            "\u001b[?25hCollecting mne>=0.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/29/7f38c7c99ca65fe4aac9054239d885c44ab7f9e8b4f65e9f2bfa489b0f38/mne-0.22.1-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.11.1)\n",
            "Collecting patool<2.0,>=1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[?25hCollecting wfdb<4.0.0,>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/be/d5572d9a8b779857f517306db178561c417456c76124cb4c9e7d234cf5a5/wfdb-3.3.0-py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.4MB/s \n",
            "\u001b[?25hCollecting scikit-learn<0.24,>=0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (3.2.2)\n",
            "Collecting h5py<4.0.0,>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c5/94e2444eb691f658fb8e3cf6cde3ae29540cf6d9ce76f0561afcdbb89136/h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 53.1MB/s \n",
            "\u001b[?25hCollecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from pyriemann>=0.2.6->moabb==0.3.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->moabb==0.3.0) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->moabb==0.3.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (1.3.1)\n",
            "Collecting threadpoolctl>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: idna>=2.2 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.22 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2016.8.2 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (3.0.4)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.0.0->moabb==0.3.0) (1.15.0)\n",
            "Building wheels for collected packages: moabb\n",
            "  Building wheel for moabb (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moabb: filename=moabb-0.3.0-cp37-none-any.whl size=116149 sha256=52fa0b02764e79974b736b6543407b1c3062fa40d185c7d6d9be7a49b13a7357\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m11wofsu/wheels/6b/6e/4c/947a2af13ece2bbe3681f59407109fd25f32aa27ca09a27808\n",
            "Successfully built moabb\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.2.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: PyYAML, entrypoint2, easyprocess, pyunpack, scipy, threadpoolctl, scikit-learn, pyriemann, mne, patool, wfdb, cached-property, h5py, moabb\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "Successfully installed PyYAML-5.4.1 cached-property-1.5.2 easyprocess-0.3 entrypoint2-0.2.4 h5py-3.2.1 mne-0.22.1 moabb-0.3.0 patool-1.12 pyriemann-0.2.6 pyunpack-0.2.2 scikit-learn-0.23.2 scipy-1.6.2 threadpoolctl-2.1.0 wfdb-3.3.0\n",
            "Collecting braindecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/be/44b7160f99d98b696caebd2b7ba43c9cadd42e4fde7fa00da54759f9a56b/Braindecode-0.5.tar.gz (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (from braindecode) (0.22.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.2.1)\n",
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/bd/f714a726f2f3106abe5a24d11b1fe8e20570323479164b829f5d4b80f7f2/skorch-0.10.0-py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->braindecode) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->braindecode) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (2.4.7)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->braindecode) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (0.23.2)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (0.8.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->braindecode) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (2.1.0)\n",
            "Building wheels for collected packages: braindecode\n",
            "  Building wheel for braindecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for braindecode: filename=Braindecode-0.5-cp37-none-any.whl size=53741 sha256=1a66d7102149d12ce77ccca8dc98cce2686226da0272e51fcc90e0f2e9db06d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/dc/b4/8db33baacda83683788e6f94a8a9dd5791bf3f65b17fd60c66\n",
            "Successfully built braindecode\n",
            "Installing collected packages: skorch, braindecode\n",
            "Successfully installed braindecode-0.5 skorch-0.10.0\n",
            "--2021-04-19 18:10:29--  https://raw.githubusercontent.com/skyli42/CSC413S2021-Team-22/master/feature_extraction.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10749 (10K) [text/plain]\n",
            "Saving to: ‘feature_extraction.py’\n",
            "\n",
            "feature_extraction. 100%[===================>]  10.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-19 18:10:29 (98.1 MB/s) - ‘feature_extraction.py’ saved [10749/10749]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN4prLIHvtla"
      },
      "source": [
        "from feature_extraction import feature_extract\n",
        "from braindecode.datasets.bbci import  BBCIDataset\n",
        "from braindecode.datasets.moabb import MOABBDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd    \n",
        "import mne\n",
        "from moabb.datasets import BNCI2014001\n",
        "from moabb.paradigms import (LeftRightImagery, MotorImagery,\n",
        "                             FilterBankMotorImagery)\n",
        "from braindecode.datasets.base import BaseDataset, BaseConcatDataset\n",
        "from braindecode.datautil.windowers import (create_fixed_length_windows,)\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "from scipy.signal import welch, spectrogram\n",
        "from scipy.ndimage.interpolation import shift\n",
        "from scipy.stats import kurtosis, skew\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from sklearn.metrics import cohen_kappa_score, recall_score, precision_score\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sGPbnKWdxD9"
      },
      "source": [
        "# Gathering + Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EBMb5F9JnFx"
      },
      "source": [
        "code_dict = {'feet':0, 'left_hand':1, 'right_hand':2, 'tongue':3}\n",
        "\n",
        "def XY_toTorch(X, Y, device):\n",
        "  # print(X.shape)\n",
        "  newX = torch.Tensor(X).reshape(X.shape[0], X.shape[1]*X.shape[2], X.shape[3])\n",
        "  newY = torch.Tensor(Y).long()\n",
        "  return newX.to(device), newY.to(device)\n",
        "\n",
        "def reshape_X(X):\n",
        "  return X.transpose(1, 2).transpose(0, 1)\n",
        "\n",
        "def create_Loaders(subjects, opts, seed=1): \n",
        "  \n",
        "  X_train, y_train, X_val, y_val, X_test, y_test = feature_extract(\"BNCI2014001\", subjects, opts.window_size, opts.augmentation_factor, opts.augmentation_noise, seed=seed) \n",
        "\n",
        "  # X_train = X_train[..., 5:15]\n",
        "  # X_val = X_val[..., 5:15]\n",
        "  # X_test = X_test[..., 5:15]\n",
        "\n",
        "  X_train, y_train = XY_toTorch(X_train, y_train, opts.device)\n",
        "  X_val, y_val = XY_toTorch(X_val, y_val, opts.device)\n",
        "  X_test, y_test = XY_toTorch(X_test, y_test, opts.device)\n",
        "  train = TensorDataset(X_train, y_train) \n",
        "  val = TensorDataset(X_val, y_val)\n",
        "  test = TensorDataset(X_test, y_test)\n",
        "  \n",
        "  train = DataLoader(train, batch_size=opts.batch_size)\n",
        "  val = DataLoader(val, batch_size=opts.batch_size)\n",
        "  test = DataLoader(test, batch_size=opts.batch_size)\n",
        "  return train, val, test, X_train.shape[2], X_train.shape[1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qWZBGr4M3jR"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JdK32xLM4xP"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, n_timesteps, n_channels, n_heads, en_hidden, de_hidden, n_transformer_layers, n_outputs, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.n_timesteps = n_timesteps\n",
        "        self.n_channels = n_channels\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(n_channels, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(n_channels, n_heads, en_hidden, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, n_transformer_layers)\n",
        "        self.decoder = nn.Sequential(\n",
        "                        nn.Linear(n_timesteps*n_channels, 2*de_hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(dropout),\n",
        "                        nn.Linear(2*de_hidden, de_hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(de_hidden, n_outputs)\n",
        "                      )\n",
        "        \n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 2.0\n",
        "        for layer in self.decoder:\n",
        "          if hasattr(layer, 'weight'):\n",
        "            nn.init.zeros_(layer.weight)\n",
        "            nn.init.uniform_(layer.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, None).transpose(0, 1).reshape(-1, self.n_timesteps*self.n_channels)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhRM0J9J5BT"
      },
      "source": [
        "# Training Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv26gZZiKlaS"
      },
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)\n",
        "\n",
        "def get_accuracy(model, data, device):\n",
        "    preds = torch.empty(0).to(device)\n",
        "    y_true= torch.empty(0).to(device)\n",
        "    for X, y in data:\n",
        "      pred = torch.argmax(model(reshape_X(X)),1)\n",
        "      preds = torch.cat((preds, pred))\n",
        "      y_true = torch.cat((y_true, y))\n",
        "    kappa_score = cohen_kappa_score(preds.cpu(), y_true.cpu())\n",
        "    precision = precision_score(y_true.cpu(), preds.cpu(), average='macro')\n",
        "    recall = recall_score(y_true.cpu(), preds.cpu(), average='macro')\n",
        "    return torch.sum((preds==y_true).long()).item()/len(preds), kappa_score, precision, recall\n",
        "\n",
        "def compute_loss(data, model, criterion, optimizer, scheduler, opts):\n",
        "    losses = []\n",
        "    for X, y in data:\n",
        "        outputs = model(reshape_X(X))\n",
        "        # print(outputs)\n",
        "        loss = criterion(outputs, y)\n",
        "        losses.append(loss.item())\n",
        "        ## training if an optimizer is provided\n",
        "        if optimizer:\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          # nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    return losses"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMIG9TkqJ0p6"
      },
      "source": [
        "def training_loop(train, val, encoder, criterion, optimizer, scheduler, opts):\n",
        "\n",
        "    best_val_loss = 1e6\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    mean_train_losses = []\n",
        "    mean_val_losses = []\n",
        "\n",
        "    early_stopping_counter = 0\n",
        "    \n",
        "    for epoch in range(opts.nepochs):\n",
        "\n",
        "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
        "        \n",
        "        train_loss = compute_loss(train, encoder, criterion, optimizer, scheduler, opts)\n",
        "        val_loss = compute_loss(val, encoder, criterion, None, None, opts)\n",
        "\n",
        "        mean_train_loss = np.mean(train_loss)\n",
        "        mean_val_loss = np.mean(val_loss)\n",
        "\n",
        "        if mean_val_loss < best_val_loss:\n",
        "            best_val_loss = mean_val_loss\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        \n",
        "        if early_stopping_counter > opts.early_stopping_patience:\n",
        "            print(\"Validation loss has not improved in {} epochs, stopping early\".format(opts.early_stopping_patience))\n",
        "            print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
        "            return (mean_train_losses, mean_val_losses)\n",
        "\n",
        "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f}\".format(epoch, mean_train_loss, mean_val_loss))\n",
        "        train_losses += train_loss\n",
        "        val_losses += val_loss\n",
        "\n",
        "        mean_train_losses.append(mean_train_loss)\n",
        "        mean_val_losses.append(mean_val_loss)\n",
        "\n",
        "    print(\"Obtained lowest validation loss of: {}\".format(best_val_loss))\n",
        "    return (mean_train_losses, mean_val_losses)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLL3Ou0ZKAgT"
      },
      "source": [
        "def train(opts, train, val, test):\n",
        "    encoder = TransformerModel(opts.timesteps, opts.channels, opts.heads, opts.en_hidden, opts.de_hidden, opts.transformer_layers, opts.outputs, opts.dropout)\n",
        "\n",
        "    if opts.cuda:\n",
        "        encoder.cuda()\n",
        "        print(\"Moved models to GPU!\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(list(encoder.parameters()), lr=opts.learning_rate, weight_decay=opts.l2_reg)  \n",
        "    # optimizer = torch.optim.SGD(encoder.parameters(), lr=opts.learning_rate, momentum= opts.momentum,weight_decay=opts.l2_reg)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=opts.lr_decay)\n",
        "\n",
        "    try:\n",
        "        losses = training_loop(train, val, encoder, \n",
        "                               criterion, optimizer, scheduler, opts)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return encoder, losses\n",
        "      \n",
        "    return encoder, losses"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8UUCKC_KI_1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvsmfig4KLWN"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfX0w4h0KHv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6941255-a017-4c91-ecc5-efe30814c934"
      },
      "source": [
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
        "device = 'cuda' if cuda else 'cpu'\n",
        "if cuda:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "options = AttrDict()\n",
        "dict_op = {\n",
        "  'augmentation_factor': 1,\n",
        "  'augmentation_noise': 0.1,\n",
        "  'window_size':75,\n",
        "  'batch_size': 100,\n",
        "  'device': device\n",
        "}\n",
        "options.update(dict_op)\n",
        "\n",
        "train_data, val_data, test_data, n_timesteps, n_channels = create_Loaders([1], options, 24)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/moabb/datasets/download.py:52: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n",
            "  set_config(key, osp.join(osp.expanduser(\"~\"), \"mne_data\"))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Calculating psd\n",
            "Calculating Freq Transform\n",
            "Calculating bands (Alpha, Beta, ...ect)\n",
            "Calculating Delta power\n",
            "Calculating Theta power\n",
            "Calculating Alpha power\n",
            "Calculating Beta power\n",
            "Calculating Gama power\n",
            "PSD shape:  (345, 22, 5, 28)\n",
            "Calculating kertosis\n",
            "Calculating Abs AUC\n",
            "Calculating zeros\n",
            "Calcualteing mean\n",
            "Calculating var\n",
            "Calculating skew\n",
            "Calculating pkpk\n",
            "Concatenate Features\n",
            "Calculating psd\n",
            "Calculating Freq Transform\n",
            "Calculating bands (Alpha, Beta, ...ect)\n",
            "Calculating Delta power\n",
            "Calculating Theta power\n",
            "Calculating Alpha power\n",
            "Calculating Beta power\n",
            "Calculating Gama power\n",
            "PSD shape:  (115, 22, 5, 28)\n",
            "Calculating kertosis\n",
            "Calculating Abs AUC\n",
            "Calculating zeros\n",
            "Calcualteing mean\n",
            "Calculating var\n",
            "Calculating skew\n",
            "Calculating pkpk\n",
            "Concatenate Features\n",
            "Calculating psd\n",
            "Calculating Freq Transform\n",
            "Calculating bands (Alpha, Beta, ...ect)\n",
            "Calculating Delta power\n",
            "Calculating Theta power\n",
            "Calculating Alpha power\n",
            "Calculating Beta power\n",
            "Calculating Gama power\n",
            "PSD shape:  (116, 22, 5, 28)\n",
            "Calculating kertosis\n",
            "Calculating Abs AUC\n",
            "Calculating zeros\n",
            "Calcualteing mean\n",
            "Calculating var\n",
            "Calculating skew\n",
            "Calculating pkpk\n",
            "Concatenate Features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWCRUta4KP5z"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hatbR8LwKQvs",
        "outputId": "53360023-cf4d-4aae-d6c4-560552bb25e5"
      },
      "source": [
        "dict_op = {\n",
        "  'nepochs':1000,\n",
        "  'learning_rate':0.1,\n",
        "  'lr_decay':0.999,\n",
        "  'l2_reg': 0.0001,\n",
        "  'momentum': 0.9,\n",
        "  'en_hidden':400, \n",
        "  'de_hidden': 400,\n",
        "  'timesteps': n_timesteps,\n",
        "  'channels': n_channels,\n",
        "  'heads': 4,\n",
        "  'transformer_layers': 12,\n",
        "  'outputs': 4,\n",
        "  'dropout': 0.1,\n",
        "  'cuda':True,\n",
        "  'early_stopping_patience': 100\n",
        "}\n",
        "options.update(dict_op)\n",
        "model, loss = train(options, train_data, val_data, test_data)\n",
        "print(\"Train Accuracy: {}, Train Kappa: {}, Train Precision: {}, Train Recall: {}\".format(*get_accuracy(model, train_data, device)))\n",
        "print(\"Val Accuracy: {}, Val Kappa: {}, Val Precision: {}, Val Recall: {}\".format(*get_accuracy(model, val_data, device)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 703171.600 | Val loss: 239026.070\n",
            "Epoch:   1 | Train loss: 266909.859 | Val loss: 167559.688\n",
            "Epoch:   2 | Train loss: 97305.844 | Val loss: 61748.494\n",
            "Epoch:   3 | Train loss: 60256.947 | Val loss: 23943.024\n",
            "Epoch:   4 | Train loss: 19034.979 | Val loss: 6609.297\n",
            "Epoch:   5 | Train loss: 12218.180 | Val loss: 9665.341\n",
            "Epoch:   6 | Train loss: 8779.949 | Val loss: 9862.020\n",
            "Epoch:   7 | Train loss: 8377.884 | Val loss: 8854.910\n",
            "Epoch:   8 | Train loss: 6493.881 | Val loss: 5916.672\n",
            "Epoch:   9 | Train loss: 5318.562 | Val loss: 3261.124\n",
            "Epoch:  10 | Train loss: 3910.838 | Val loss: 3318.490\n",
            "Epoch:  11 | Train loss: 2745.020 | Val loss: 1372.961\n",
            "Epoch:  12 | Train loss: 1810.456 | Val loss: 876.226\n",
            "Epoch:  13 | Train loss: 1012.732 | Val loss: 835.796\n",
            "Epoch:  14 | Train loss: 878.579 | Val loss: 484.156\n",
            "Epoch:  15 | Train loss: 473.498 | Val loss: 461.013\n",
            "Epoch:  16 | Train loss: 389.355 | Val loss: 325.327\n",
            "Epoch:  17 | Train loss: 294.121 | Val loss: 228.807\n",
            "Epoch:  18 | Train loss: 208.045 | Val loss: 161.400\n",
            "Epoch:  19 | Train loss: 158.863 | Val loss: 153.898\n",
            "Epoch:  20 | Train loss: 134.319 | Val loss: 128.837\n",
            "Epoch:  21 | Train loss: 121.555 | Val loss: 117.540\n",
            "Epoch:  22 | Train loss: 91.417 | Val loss: 103.970\n",
            "Epoch:  23 | Train loss: 104.412 | Val loss: 105.890\n",
            "Epoch:  24 | Train loss: 94.942 | Val loss: 94.366\n",
            "Epoch:  25 | Train loss: 113.314 | Val loss: 130.789\n",
            "Epoch:  26 | Train loss: 109.322 | Val loss: 96.274\n",
            "Epoch:  27 | Train loss: 88.734 | Val loss: 73.427\n",
            "Epoch:  28 | Train loss: 91.669 | Val loss: 71.800\n",
            "Epoch:  29 | Train loss: 70.421 | Val loss: 74.801\n",
            "Epoch:  30 | Train loss: 75.147 | Val loss: 53.940\n",
            "Epoch:  31 | Train loss: 69.267 | Val loss: 57.856\n",
            "Epoch:  32 | Train loss: 66.972 | Val loss: 77.267\n",
            "Epoch:  33 | Train loss: 55.896 | Val loss: 84.399\n",
            "Epoch:  34 | Train loss: 59.315 | Val loss: 46.171\n",
            "Epoch:  35 | Train loss: 53.825 | Val loss: 56.357\n",
            "Epoch:  36 | Train loss: 50.114 | Val loss: 37.931\n",
            "Epoch:  37 | Train loss: 36.051 | Val loss: 19.231\n",
            "Epoch:  38 | Train loss: 16.557 | Val loss: 4.176\n",
            "Epoch:  39 | Train loss: 4.800 | Val loss: 6.487\n",
            "Epoch:  40 | Train loss: 1.781 | Val loss: 1.781\n",
            "Epoch:  41 | Train loss: 3.036 | Val loss: 1.468\n",
            "Epoch:  42 | Train loss: 1.403 | Val loss: 1.879\n",
            "Epoch:  43 | Train loss: 1.398 | Val loss: 1.398\n",
            "Epoch:  44 | Train loss: 1.434 | Val loss: 1.409\n",
            "Epoch:  45 | Train loss: 1.638 | Val loss: 1.384\n",
            "Epoch:  46 | Train loss: 1.389 | Val loss: 1.383\n",
            "Epoch:  47 | Train loss: 1.394 | Val loss: 1.385\n",
            "Epoch:  48 | Train loss: 1.466 | Val loss: 1.383\n",
            "Epoch:  49 | Train loss: 1.401 | Val loss: 1.387\n",
            "Epoch:  50 | Train loss: 1.390 | Val loss: 1.385\n",
            "Epoch:  51 | Train loss: 1.432 | Val loss: 1.384\n",
            "Epoch:  52 | Train loss: 1.387 | Val loss: 1.386\n",
            "Epoch:  53 | Train loss: 1.431 | Val loss: 1.551\n",
            "Epoch:  54 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch:  55 | Train loss: 1.389 | Val loss: 1.386\n",
            "Epoch:  56 | Train loss: 1.554 | Val loss: 1.386\n",
            "Epoch:  57 | Train loss: 1.385 | Val loss: 1.384\n",
            "Epoch:  58 | Train loss: 3.261 | Val loss: 1.385\n",
            "Epoch:  59 | Train loss: 1.386 | Val loss: 1.385\n",
            "Epoch:  60 | Train loss: 1.415 | Val loss: 1.385\n",
            "Epoch:  61 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  62 | Train loss: 1.390 | Val loss: 1.384\n",
            "Epoch:  63 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  64 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  65 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  66 | Train loss: 1.386 | Val loss: 1.385\n",
            "Epoch:  67 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  68 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch:  69 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  70 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  71 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch:  72 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  73 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  74 | Train loss: 1.388 | Val loss: 4.319\n",
            "Epoch:  75 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  76 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  77 | Train loss: 1.389 | Val loss: 1.395\n",
            "Epoch:  78 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  79 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  80 | Train loss: 1.388 | Val loss: 1.521\n",
            "Epoch:  81 | Train loss: 1.380 | Val loss: 1.383\n",
            "Epoch:  82 | Train loss: 1.388 | Val loss: 1.408\n",
            "Epoch:  83 | Train loss: 1.389 | Val loss: 1.385\n",
            "Epoch:  84 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch:  85 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  86 | Train loss: 1.387 | Val loss: 1.384\n",
            "Epoch:  87 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch:  88 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch:  89 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch:  90 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch:  91 | Train loss: 1.623 | Val loss: 1.385\n",
            "Epoch:  92 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch:  93 | Train loss: 5.078 | Val loss: 1.384\n",
            "Epoch:  94 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch:  95 | Train loss: 1.386 | Val loss: 2.110\n",
            "Epoch:  96 | Train loss: 1.501 | Val loss: 1.443\n",
            "Epoch:  97 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch:  98 | Train loss: 1.541 | Val loss: 1.632\n",
            "Epoch:  99 | Train loss: 1.404 | Val loss: 1.385\n",
            "Epoch: 100 | Train loss: 3.690 | Val loss: 2.214\n",
            "Epoch: 101 | Train loss: 1.424 | Val loss: 1.384\n",
            "Epoch: 102 | Train loss: 1.618 | Val loss: 1.395\n",
            "Epoch: 103 | Train loss: 1.389 | Val loss: 1.413\n",
            "Epoch: 104 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch: 105 | Train loss: 1.562 | Val loss: 1.794\n",
            "Epoch: 106 | Train loss: 1.388 | Val loss: 1.464\n",
            "Epoch: 107 | Train loss: 1.412 | Val loss: 1.384\n",
            "Epoch: 108 | Train loss: 1.388 | Val loss: 1.423\n",
            "Epoch: 109 | Train loss: 1.942 | Val loss: 1.384\n",
            "Epoch: 110 | Train loss: 1.435 | Val loss: 1.384\n",
            "Epoch: 111 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch: 112 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch: 113 | Train loss: 1.440 | Val loss: 1.385\n",
            "Epoch: 114 | Train loss: 1.408 | Val loss: 1.385\n",
            "Epoch: 115 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 116 | Train loss: 1.416 | Val loss: 1.384\n",
            "Epoch: 117 | Train loss: 1.435 | Val loss: 1.384\n",
            "Epoch: 118 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 119 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 120 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 121 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 122 | Train loss: 1.389 | Val loss: 1.384\n",
            "Epoch: 123 | Train loss: 1.403 | Val loss: 1.503\n",
            "Epoch: 124 | Train loss: 1.387 | Val loss: 1.385\n",
            "Epoch: 125 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 126 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 127 | Train loss: 1.402 | Val loss: 1.385\n",
            "Epoch: 128 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 129 | Train loss: 1.420 | Val loss: 1.385\n",
            "Epoch: 130 | Train loss: 1.486 | Val loss: 1.384\n",
            "Epoch: 131 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 132 | Train loss: 1.452 | Val loss: 1.384\n",
            "Epoch: 133 | Train loss: 1.384 | Val loss: 1.385\n",
            "Epoch: 134 | Train loss: 1.390 | Val loss: 1.384\n",
            "Epoch: 135 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 136 | Train loss: 1.387 | Val loss: 1.915\n",
            "Epoch: 137 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 138 | Train loss: 1.387 | Val loss: 1.384\n",
            "Epoch: 139 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 140 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 141 | Train loss: 1.437 | Val loss: 1.384\n",
            "Epoch: 142 | Train loss: 1.388 | Val loss: 1.384\n",
            "Epoch: 143 | Train loss: 1.538 | Val loss: 1.428\n",
            "Epoch: 144 | Train loss: 1.387 | Val loss: 1.384\n",
            "Epoch: 145 | Train loss: 1.388 | Val loss: 1.385\n",
            "Epoch: 146 | Train loss: 1.506 | Val loss: 1.384\n",
            "Validation loss has not improved in 100 epochs, stopping early\n",
            "Obtained lowest validation loss of: 1.382835865020752\n",
            "Train Accuracy: 0.2608695652173913, Train Kappa: -0.003845363883246966, Train Precision: 0.06540697674418605, Train Recall: 0.24725274725274726\n",
            "Val Accuracy: 0.25217391304347825, Val Kappa: 0.0, Val Precision: 0.06304347826086956, Val Recall: 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqxYJ5hbQgG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "3eb20d24-a42c-4499-a172-7fec1f13f43d"
      },
      "source": [
        "plt.figure(figsize=(12, 9), dpi=80)\n",
        "train_loss, val_loss = loss\n",
        "plt.ylim(0, 100)\n",
        "plt.plot(train_loss, label=\"Training Loss\")\n",
        "plt.plot(val_loss, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 960x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGHR_moKYLWw",
        "outputId": "f2adb2a6-111b-4345-fca9-8862e92056e0"
      },
      "source": [
        "print(\"Test Accuracy: {}, Test Kappa: {}, Test Precision: {}, Test Recall: {}\".format(*get_accuracy(model, test_data, device)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.20689655172413793, Test Kappa: 0.0, Test Precision: 0.05172413793103448, Test Recall: 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}