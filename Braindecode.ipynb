{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Braindecode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV5zrtyb2rkI",
        "outputId": "bab8b3a9-4491-4afd-acae-6da99c9f474b"
      },
      "source": [
        "!pip install download\n",
        "!python -c \"from download import download; download('https://raw.githubusercontent.com/NeuroTechX/moabb/master/requirements.txt', 'requirements.txt', replace=True)\"\n",
        "!pip install -r requirements.txt\n",
        "!rm requirements.txt\n",
        "!pip install -U https://github.com/NeuroTechX/moabb/archive/master.zip\n",
        "!pip install braindecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: download in /usr/local/lib/python3.7/dist-packages (0.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from download) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from download) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from download) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->download) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->download) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->download) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->download) (1.24.3)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/download/download.py\", line 208, in _fetch_file\n",
            "    u = urllib.request.urlopen(req, timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 531, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 641, in http_response\n",
            "    'http', request, response, code, msg, hdrs)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 569, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 649, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 404: Not Found\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/download/download.py\", line 124, in download\n",
            "    progressbar=progressbar,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/download/download.py\", line 279, in _fetch_file\n",
            "    \" Dataset fetching aborted.\\nError: %s\" % (url, ee)\n",
            "RuntimeError: Error while fetching file https://raw.githubusercontent.com/NeuroTechX/moabb/master/requirements.txt. Dataset fetching aborted.\n",
            "Error: HTTP Error 404: Not Found\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
            "rm: cannot remove 'requirements.txt': No such file or directory\n",
            "Collecting https://github.com/NeuroTechX/moabb/archive/master.zip\n",
            "  Using cached https://github.com/NeuroTechX/moabb/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: mne>=0.19 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (5.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyunpack<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: patool<2.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn<0.24,>=0.23 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: pyriemann>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.2.6)\n",
            "Requirement already satisfied, skipping upgrade: wfdb<4.0.0,>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (1.6.2)\n",
            "Requirement already satisfied, skipping upgrade: coloredlogs<16.0,>=15.0 in /usr/local/lib/python3.7/dist-packages (from moabb==0.3.0) (15.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->moabb==0.3.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->moabb==0.3.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->moabb==0.3.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->moabb==0.3.0) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: entrypoint2 in /usr/local/lib/python3.7/dist-packages (from pyunpack<0.3.0,>=0.2.2->moabb==0.3.0) (0.2.3)\n",
            "Requirement already satisfied, skipping upgrade: easyprocess in /usr/local/lib/python3.7/dist-packages (from pyunpack<0.3.0,>=0.2.2->moabb==0.3.0) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->moabb==0.3.0) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24,>=0.23->moabb==0.3.0) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24,>=0.23->moabb==0.3.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: idna>=2.2 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2016.8.2 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.22 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from wfdb<4.0.0,>=3.3.0->moabb==0.3.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py<4.0.0,>=3.0.0->moabb==0.3.0) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: humanfriendly>=9.1 in /usr/local/lib/python3.7/dist-packages (from coloredlogs<16.0,>=15.0->moabb==0.3.0) (9.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.0.0->moabb==0.3.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: argparse in /usr/local/lib/python3.7/dist-packages (from entrypoint2->pyunpack<0.3.0,>=0.2.2->moabb==0.3.0) (1.4.0)\n",
            "Building wheels for collected packages: moabb\n",
            "  Building wheel for moabb (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moabb: filename=moabb-0.3.0-cp37-none-any.whl size=107261 sha256=5025e1bc6fb14f242a0e5d43197c1ac15638c071ded4a2ad43ca495daf592309\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y6dcs75z/wheels/6b/6e/4c/947a2af13ece2bbe3681f59407109fd25f32aa27ca09a27808\n",
            "Successfully built moabb\n",
            "Installing collected packages: moabb\n",
            "  Found existing installation: moabb 0.3.0\n",
            "    Uninstalling moabb-0.3.0:\n",
            "      Successfully uninstalled moabb-0.3.0\n",
            "Successfully installed moabb-0.3.0\n",
            "Requirement already satisfied: braindecode in /usr/local/lib/python3.7/dist-packages (0.5)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (from braindecode) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.1.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.2.1)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (from braindecode) (0.22.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from braindecode) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from braindecode) (1.6.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (0.23.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch->braindecode) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->braindecode) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->braindecode) (2018.9)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->braindecode) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->braindecode) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch->braindecode) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->braindecode) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LskZOWi3ksS",
        "outputId": "d2edabc1-4018-46b8-a2aa-95254fb20561"
      },
      "source": [
        "from braindecode.datasets.moabb import MOABBDataset\n",
        "import mne\n",
        "\n",
        "subject_id = 3\n",
        "dataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n",
            "48 events found\n",
            "Event IDs: [1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEu3fluq6jTG",
        "outputId": "a024f8b7-a9eb-4d60-bcf2-5f5aeefa2d6d"
      },
      "source": [
        "from braindecode.datautil.preprocess import exponential_moving_standardize\n",
        "from braindecode.datautil.preprocess import MNEPreproc, NumpyPreproc, preprocess\n",
        "\n",
        "low_cut_hz = 4.  # low cut frequency for filtering\n",
        "high_cut_hz = 38.  # high cut frequency for filtering\n",
        "# Parameters for exponential moving standardization\n",
        "factor_new = 1e-3\n",
        "init_block_size = 1000\n",
        "\n",
        "preprocessors = [\n",
        "    # keep only EEG sensors\n",
        "    MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False),\n",
        "    # convert from volt to microvolt, directly modifying the numpy array\n",
        "    NumpyPreproc(fn=lambda x: x * 1e6),\n",
        "    # bandpass filter\n",
        "    MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz),\n",
        "    # exponential moving standardization\n",
        "    NumpyPreproc(fn=exponential_moving_standardize, factor_new=factor_new,\n",
        "        init_block_size=init_block_size)\n",
        "]\n",
        "\n",
        "# Transform the data\n",
        "preprocess(dataset, preprocessors)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N3h_iU-8Jlq",
        "outputId": "e2034024-799e-4e0f-ff6f-52ab2fdc4918"
      },
      "source": [
        "import numpy as np\n",
        "from braindecode.datautil.windowers import create_windows_from_events\n",
        "\n",
        "trial_start_offset_seconds = -0.5\n",
        "# Extract sampling frequency, check that they are same in all datasets\n",
        "sfreq = dataset.datasets[0].raw.info['sfreq']\n",
        "assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
        "# Calculate the trial start offset in samples.\n",
        "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
        "\n",
        "# Create windows using braindecode function for this. It needs parameters to define how\n",
        "# trials should be used.\n",
        "windows_dataset = create_windows_from_events(\n",
        "    dataset,\n",
        "    trial_start_offset_samples=trial_start_offset_samples,\n",
        "    trial_stop_offset_samples=0,\n",
        "    preload=True,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Adding metadata with 4 columns\n",
            "Replacing existing metadata with 4 columns\n",
            "48 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 48 events and 1125 original time points ...\n",
            "0 bad epochs dropped\n",
            "0 bad epochs dropped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VApEIht8NJb"
      },
      "source": [
        "splitted = windows_dataset.split('session')\n",
        "train_set = splitted['session_T']\n",
        "valid_set = splitted['session_E']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo_z8vIB9NtY",
        "outputId": "ab5ab962-eda6-4e4d-a971-7edef5b7201e"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrXef_Sz8SdB"
      },
      "source": [
        "import torch\n",
        "from braindecode.util import set_random_seeds\n",
        "from braindecode.models import ShallowFBCSPNet\n",
        "\n",
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
        "device = 'cuda' if cuda else 'cpu'\n",
        "if cuda:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed = 20200220  # random seed to make results reproducible\n",
        "# Set random seed to be able to reproduce results\n",
        "set_random_seeds(seed=seed, cuda=cuda)\n",
        "\n",
        "n_classes=4\n",
        "# Extract number of chans and time steps from dataset\n",
        "n_chans = train_set[0][0].shape[0]\n",
        "input_window_samples = train_set[0][0].shape[1]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QjoE7blBNGa"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhJzI6HzF8J8"
      },
      "source": [
        "train_data = torch.Tensor(np.asarray([tup[0] for tup in train_set])).transpose(1, 2).transpose(0, 1).to(device)\n",
        "train_labels = torch.Tensor(np.asarray([tup[1] for tup in train_set])).to(device)\n",
        "train_add = [tup[2] for tup in train_set]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3G4T-k3GD5D",
        "outputId": "0727efd6-aae0-472e-faf6-75688028cd67"
      },
      "source": [
        "print(train_data.shape) # Batch size, num channels, time step\n",
        "print(train_labels.shape) # Batch size, "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1125, 288, 22])\n",
            "torch.Size([288])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBdN1ofyKGuH"
      },
      "source": [
        "From [here](https://github.com/pytorch/examples/tree/master/word_language_model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGUEngKbBkCC"
      },
      "source": [
        "import math\n",
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model).to(device)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super().__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout).to(device)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout).to(device)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers).to(device)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, n_classes).to(device)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, has_mask=True):\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return F.log_softmax(output, dim=-1)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phn74zNDLzmK"
      },
      "source": [
        "model = TransformerModel(n_chans, 2, 2048, 6)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjIZfjIND8j"
      },
      "source": [
        "bptt = 5\n",
        "def get_random_batch(train_data, train_labels):\n",
        "  total = train_data.size(1)\n",
        "  sample = np.random.choice(total, bptt)\n",
        "  return train_data[:, sample, :], train_labels[sample]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHmzBb-gLZ7r"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0 # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "import time\n",
        "def train(model):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    src_mask = model._generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_random_batch(train_data, train_labels)\n",
        "        data = train_data\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output.view(-1, n_classes), targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "NBKiyzhcOK10",
        "outputId": "3331b506-7a8e-4e14-a0f0-d9e4f868fdc6"
      },
      "source": [
        "train(model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9d3046b5d0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-f6173de7df25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-3c3e0961fa76>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, has_mask)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0msrc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.47 GiB (GPU 0; 14.76 GiB total capacity; 11.59 GiB already allocated; 817.75 MiB free; 12.93 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqZFblVzOTHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}